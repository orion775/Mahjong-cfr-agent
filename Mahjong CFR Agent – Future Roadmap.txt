# Future Roadmap – Mahjong CFR Agent

---

## 1. Oracle Curriculum & Isolated CFR Tests (v1.6.x → v1.7.x)

**Goal:**  
Demonstrate that the engine and CFR logic are robust for all win types, including interrupts and rare edge cases.

**Actions:**  
- Maintain and extend oracle states for all core scenarios: self-draw, Ron, CHI, PON, KAN, Shominkan, and others.
- Ensure each oracle test is deterministic, interpretable, and checks both terminality and reward assignment.
- Use these tests as regression coverage for every future engine/CFR refactor.

**Milestone:**  
All “oracle” win conditions are tested and pass in complete isolation.

---

## 2. Reverse Curriculum Learning (v1.7.x → v1.8.x)

**Goal:**  
Teach the agent to win from increasingly complex states, moving backward from the finish line.

**Actions:**  
- For each curriculum level, create a set of N-steps-from-win game states.
- Require the agent to reliably solve easier curriculum states before progressing to harder ones.
- At each level, use oracle tests to verify correct value propagation.
- Analyze and document generalization as the curriculum broadens.

**Milestone:**  
Agent not only solves immediate wins, but also learns optimal policies from several steps away from victory.

---

## 3. Realistic Interrupt/Claim Actions (v1.9.x)

**Goal:**  
Replace test-only hacks with true gameplay support for claiming Ron, PON, CHI, KAN, etc., as real actions.

**Actions:**  
- Extend the action space and `GameState.step()` to handle interrupt (reaction) actions.
- Implement full meld claim/priority arbitration (multiple claimers, PON > CHI > Ron, etc.).
- Update CFR logic to branch and propagate values across interrupt/reaction nodes.
- Add corresponding regression tests for all reaction and claim cases.

**Milestone:**  
Engine fully supports legal gameplay with real-time meld interrupts and claims, and CFR can train on live play sequences.

---

## 4. Full Self-Play and Partial Reward Design (v2.0.x)

**Goal:**  
Enable the agent to learn strategies from full random deals, not just controlled or oracle states, and to benefit from partial hand improvements.

**Actions:**  
- Allow CFR rollouts from any legal initial state, not just curriculum positions.
- Design and test partial/shape rewards for making melds, reaching tenpai, shanten reduction, etc.
- Confirm the agent learns non-trivial, interpretable strategies through self-play.

**Milestone:**  
Agent displays sensible play and strategic learning in full multi-agent self-play environments.

---

## 5. Info Set Abstraction & CFR+ (v2.1.x+)

**Goal:**  
Make learning scalable for real Mahjong by compressing the state/action space and optimizing regret updates.

**Actions:**  
- Enhance `get_info_set()` abstraction (track visible discards, melds, seat winds, and more).
- Integrate CFR+ or similar improved regret matching for speed and stability.
- Research and experiment with abstraction techniques (bucketing, function approximation).

**Milestone:**  
Agent uses human-like, tractable info sets and robust, scalable CFR for long-term policy learning.

---

## 6. Deep Learning Integration (v3.0.x+)

**Goal:**  
Transition from tabular CFR to Deep CFR or neural regret approximation for large-scale, real-world play.

**Actions:**  
- Implement neural networks for regret and value approximation (as in Suphx, AlphaZero for Mahjong).
- Integrate function approximation into CFR rollouts and policy distillation.
- Run large-scale experiments, add logging, and prepare for interactive human-vs-agent matches.

**Milestone:**  
Agent is capable of learning online from self-play, scaling to full-size Mahjong, and competing with strong human and AI players.

---

## 7. Ongoing/Continuous

**Testing & Debugging:**  
- All refactors must be covered by oracle/curriculum regression tests.
- Document all tricky or fragile logic in the devlog.
- Expand test coverage with every new feature or bugfix.

**Devlog & Version Tracking:**  
- Maintain complete documentation of what works, what broke, and how it was fixed.
- Log all significant features, bugs, and test coverage milestones.

---

## Visual Roadmap Table

| Phase                | Core Focus/Skill Learned           | Optimal Trigger                         |
|----------------------|------------------------------------|-----------------------------------------|
| Oracle CFR           | All win/interrupt types            | Now (ongoing, completes with coverage)  |
| Reverse Curriculum   | Stepwise/generalization learning   | Once all oracle scenarios are passing   |
| Real Interrupts      | Full gameplay w/ reactions         | After basic CFR is stable               |
| Self-Play            | Full games, partial rewards        | Engine robust for random self-play      |
| Abstraction/CFR+     | Info set and strategy compression  | Full-game state/action space too large  |
| Deep CFR             | Neural/large-scale learning        | Tabular CFR plateau, hardware available |

---

**Note:**  
This roadmap is designed to ensure each new capability is only added when the foundation is solid and regression-tested.  
At every phase, the engine and agent will be validated by strict curriculum/oracle tests and well-documented in the devlog.
